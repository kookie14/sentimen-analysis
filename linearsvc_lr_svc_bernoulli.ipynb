{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kookie14/sentimen-analysis/blob/main/linearsvc_lr_svc_bernoulli.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install unidecode\n",
        "!pip install emoji"
      ],
      "metadata": {
        "id": "sVr05_79lHFn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "pip install transformers\n",
        "pip install fastBPE\n",
        "pip install FAIRSeq"
      ],
      "metadata": {
        "id": "ppE6yy_DkJN1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install unidecode"
      ],
      "metadata": {
        "id": "Z6oXO36t4f7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import string\n",
        "import unidecode\n",
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "import emoji\n",
        "from sklearn import utils as skutils\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline, FeatureUnion\n"
      ],
      "metadata": {
        "id": "3y8uhb4-GlSu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PbMoNjKelUOk"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = '/content/drive/MyDrive/Machine Learning/data_file.csv'"
      ],
      "metadata": {
        "id": "okWLthGA-NBd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(data)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "vf8DCl7qHX18"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = df['Comment'].values, df['Rating'].values"
      ],
      "metadata": {
        "id": "Ku29wjnfHAcK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X[7]"
      ],
      "metadata": {
        "id": "sXzKGjI1SJSs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tiền xử lý "
      ],
      "metadata": {
        "id": "COMbxY5xF_tz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Chuẩn hoá về chữ thường"
      ],
      "metadata": {
        "id": "umFt1sVFGEFe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lowerCase(data):\n",
        "    data = data.lower()\n",
        "    return data"
      ],
      "metadata": {
        "id": "pgxvrq6Z-F3j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = 'Xôi dẻo, đồ ăn đậm vị. Hộp xôi được lót lá trông rất thích'\n",
        "test = lowerCase(test)\n",
        "test"
      ],
      "metadata": {
        "id": "HOxeR-q5GQlU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* xoá dấu câu"
      ],
      "metadata": {
        "id": "jyYVtqkKGfjJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_punctuations(data):\n",
        "    punct_tag = re.compile(r'[^\\w\\s]')\n",
        "    data = punct_tag.sub(r'',data)\n",
        "    return data"
      ],
      "metadata": {
        "id": "KA6Sy_YJGe3U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "remove_punctuations(test)"
      ],
      "metadata": {
        "id": "g4wxwcL8GbqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* xoá thẻ html"
      ],
      "metadata": {
        "id": "1KEK1b7tG2HJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_html(data):\n",
        "    html_tag=re.compile(r'<.*?>')\n",
        "    data=html_tag.sub(r'',data)\n",
        "    return data"
      ],
      "metadata": {
        "id": "wDJQMLApGq7i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* xoá dữ liệu URL"
      ],
      "metadata": {
        "id": "O8PuZvA7G7tF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_url(data):\n",
        "    url_clean= re.compile(r\"https://\\S+|www\\.\\S+\")\n",
        "    data=url_clean.sub(r'',data)\n",
        "    return data"
      ],
      "metadata": {
        "id": "RXUqxwKSG56Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* remove dấu xuống dòng"
      ],
      "metadata": {
        "id": "wJ0o5c7PHBV0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_n(data):\n",
        "    html_tag=re.compile(r'\\n')\n",
        "    data=html_tag.sub(r' ',data)\n",
        "    return data"
      ],
      "metadata": {
        "id": "FaVt-dgpHASR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* xoá icon, emoji"
      ],
      "metadata": {
        "id": "iWlVl94MHLQY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_emoji(data):\n",
        "    emoji_clean= re.compile(\"[\"\n",
        "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                           u\"\\U00002702-\\U000027B0\"\n",
        "                           u\"\\U000024C2-\\U0001F251\"\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "    data=emoji_clean.sub(r'',data)\n",
        "    url_clean= re.compile(r\"https://\\S+|www\\.\\S+\")\n",
        "    data=url_clean.sub(r'',data)\n",
        "    return data"
      ],
      "metadata": {
        "id": "m93Zi6kJHIpM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install unidecode"
      ],
      "metadata": {
        "id": "itTfEwWoiwT9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def removeTone(data):\n",
        "  return unidecode.unidecode(data)"
      ],
      "metadata": {
        "id": "aIW0YUqCdcMC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def removeConsecutiveSpaces(data):\n",
        "  return ' '.join(data.split())"
      ],
      "metadata": {
        "id": "tYa50qBEiujM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_n(data):\n",
        "    html_tag=re.compile(r'\\n')\n",
        "    data=html_tag.sub(r' ',data)\n",
        "    return data"
      ],
      "metadata": {
        "id": "jLELnFi1i_7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_Iter(text):\n",
        "  text = re.sub(r'([A-Z])\\1+', lambda m: m.group(1).upper(), text, flags=re.IGNORECASE)\n",
        "  return text"
      ],
      "metadata": {
        "id": "zG2ODe9Sjk4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = 'đẹppppp quasssss'\n",
        "print(remove_Iter(test))"
      ],
      "metadata": {
        "id": "7OrlzIKKjxF0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Comment'] = df['Comment'].apply(lambda z: remove_punctuations(z))\n",
        "\n",
        "df['Comment'] = df['Comment'].apply(lambda z: remove_n(z))\n",
        "\n",
        "df['Comment'] = df['Comment'].apply(lambda z: remove_html(z))\n",
        "\n",
        "df['Comment'] = df['Comment'].apply(lambda z: remove_url(z))\n",
        "\n",
        "df['Comment'] = df['Comment'].apply(lambda z: remove_emoji(z))\n",
        "\n",
        "df['Comment'] = df['Comment'].apply(lambda z: removeTone(z))\n",
        "\n",
        "df['Comment'] = df['Comment'].apply(lambda z: removeConsecutiveSpaces(z))\n",
        "\n",
        "df['Comment'] = df['Comment'].apply(lambda z: remove_n(z))\n",
        "\n",
        "df['Comment'] = df['Comment'].apply(lambda z: remove_Iter(z))\n",
        "\n",
        "df['Comment'] = df['Comment'].apply(lambda z: lowerCase(z))\n"
      ],
      "metadata": {
        "id": "iJXL_ZA1rM_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "TH_WGjl4dU0P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = []\n",
        "for index, values in enumerate(y):\n",
        "  if y[index] < 6: values = 0\n",
        "  else: values = 1\n",
        "  labels.append(values)"
      ],
      "metadata": {
        "id": "7VLM_kVWeV6s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_data = pd.DataFrame({ 'Comment':df['Comment'], 'Label': labels})\n",
        "clean_data.to_csv('/content/drive/MyDrive/Machine Learning/clean_data.csv')"
      ],
      "metadata": {
        "id": "rI5CKRGtelf2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_data.head()"
      ],
      "metadata": {
        "id": "62YjV36bf0lT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts = clean_data['Comment'].values\n",
        "label = clean_data['Label'].values"
      ],
      "metadata": {
        "id": "EzDDUQgyhHo7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SlKs9U8o4-wz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn import metrics"
      ],
      "metadata": {
        "id": "zchrM1lqyJv_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = clean_data['Comment'].values\n",
        "y_train =  clean_data['Label'].values"
      ],
      "metadata": {
        "id": "nNc4G8Auxg3l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, l_train, l_test = train_test_split(X_train,y_train, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "RLQL_jUO4Sq6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vect = TfidfVectorizer(max_features=5000,stop_words='english')\n",
        "vect"
      ],
      "metadata": {
        "id": "icJDA11A-XT7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xEmCZEe---1R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_dtm = vect.fit_transform(x_train)\n",
        "test_X_dtm = vect.transform(x_test)"
      ],
      "metadata": {
        "id": "QqDnRjIU-nG5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = ['0', '1']\n",
        "submit = []\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "logreg = LogisticRegression(C=12.0)\n",
        "for label in labels:\n",
        "   print('... Processing {}'.format(label))\n",
        "   logreg.fit(X_dtm, l_train)\n",
        "   y_pre = logreg.predict(X_dtm)\n",
        "   print('Training Accuracy is {}'.format(accuracy_score(l_train,y_pre)))\n",
        "   test_y = logreg.predict(test_X_dtm)\n",
        "   test_y_prob = logreg.predict(test_X_dtm)\n",
        "   print('Training Accuracy is {}'.format(accuracy_score(l_test,test_y_prob)))"
      ],
      "metadata": {
        "id": "Rwkwz-lB_O9c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer\n",
        "from sklearn.svm import LinearSVC\n",
        "classifier =  LinearSVC(fit_intercept = True,multi_class='ovr', C=1)\n",
        "step = []\n",
        "step.append(('CountVectorizer', CountVectorizer(ngram_range=(1,4),max_df=0.5, min_df=5)))\n",
        "step.append(('tfidf', TfidfTransformer(use_idf=False, sublinear_tf = True,norm='l2',smooth_idf=True)))\n",
        "step.append(('classifiers',classifier))\n",
        "clf = Pipeline(step)\n",
        "clf.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "Bw-4NYIXld7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9LvBOUbwCqyT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cDGtfxe4DaP_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_file = '/content/drive/MyDrive/Machine Learning/test.csv'\n",
        "test = pd.read_csv(test_file)\n",
        "test.head()"
      ],
      "metadata": {
        "id": "y5_ktR_oAabQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test['Comment'] = test['Comment'].apply(lambda z: remove_punctuations(str(z)))\n",
        "\n",
        "test['Comment'] = test['Comment'].apply(lambda z: remove_n(z))\n",
        "\n",
        "test['Comment'] = test['Comment'].apply(lambda z: remove_html(z))\n",
        "\n",
        "test['Comment'] = test['Comment'].apply(lambda z: remove_url(z))\n",
        "\n",
        "test['Comment'] = test['Comment'].apply(lambda z: remove_emoji(z))\n",
        "\n",
        "test['Comment'] = test['Comment'].apply(lambda z: removeTone(z))\n",
        "\n",
        "test['Comment'] = test['Comment'].apply(lambda z: removeConsecutiveSpaces(z))\n",
        "\n",
        "test['Comment'] = test['Comment'].apply(lambda z: remove_n(z))\n",
        "\n",
        "test['Comment'] = test['Comment'].apply(lambda z: remove_Iter(z))\n",
        "\n",
        "test['Comment'] = test['Comment'].apply(lambda z: lowerCase(str(z)))"
      ],
      "metadata": {
        "id": "ETmKQXMH0G6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test.head()"
      ],
      "metadata": {
        "id": "INQGE7H101e-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = test['Comment'].values\n",
        "text = np.array(text)\n",
        "text_vec = vect.transform(text)\n",
        "for label in labels:\n",
        "  print('... Processing {}'.format(label))\n",
        "  logreg.fit(X_dtm, l_train)\n",
        "  y_pre = logreg.predict(X_dtm)\n",
        "  print('Training Accuracy is {}'.format(accuracy_score(l_train,y_pre)))\n",
        "  test_y_prob = logreg.predict_proba()[:,1]\n",
        "    "
      ],
      "metadata": {
        "id": "a9gyPKb81_Dx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test =  clf.predict(text)"
      ],
      "metadata": {
        "id": "eOpwGrfj1wZb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VUCqXsxYCRh9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submit = pd.DataFrame({'RevId': test['RevId'], 'Rating': test_y_prob})\n",
        "submit.to_csv('/content/drive/MyDrive/Machine Learning/submit412.csv')\n",
        "submit[0:10]"
      ],
      "metadata": {
        "id": "37uL91uk2JWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import confusion_matrix, classification_report"
      ],
      "metadata": {
        "id": "dWBAYpLh6F6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer\n",
        "from sklearn.svm import LinearSVC\n",
        "x = LinearSVC(fit_intercept = True,multi_class='crammer_singer', C=1)\n",
        "step1 = []\n",
        "step1.append(('CountVectorizer', CountVectorizer(ngram_range=(1,4),max_df=0.5, min_df=5)))\n",
        "step1.append(('tfidf', TfidfTransformer(use_idf=False, sublinear_tf = True,norm='l2',smooth_idf=True)))\n",
        "step1.append(('classifiers',x))\n",
        "clf = Pipeline(step1)"
      ],
      "metadata": {
        "id": "5YEyKtKB_vQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer\n",
        "from sklearn.svm import LinearSVC\n",
        "LRmodel = LogisticRegression(C = 1, max_iter = 2000, n_jobs=-1)\n",
        "step2 = []\n",
        "step2.append(('CountVectorizer', CountVectorizer(ngram_range=(1,5),max_df=0.5, min_df=5)))\n",
        "step2.append(('tfidf', TfidfTransformer(use_idf=False, sublinear_tf = True,norm='l2',smooth_idf=True)))\n",
        "step2.append(('classifiers',LRmodel))\n",
        "clf1 = Pipeline(step2)"
      ],
      "metadata": {
        "id": "jGe_b9al6WHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, l_train, l_test = train_test_split(X_train,y_train, test_size=0.2, random_state=26105111)"
      ],
      "metadata": {
        "id": "E2mvGaxO6lOC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf.fit(x_train, l_train)"
      ],
      "metadata": {
        "id": "DU-mgbYsADrW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicty = clf.predict(x_test) \n",
        "report1 = metrics.classification_report(l_test,predicty , labels=[1,0], digits=3)\n",
        "print(report1)"
      ],
      "metadata": {
        "id": "KuTlYmRrALul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf1.fit(x_train, l_train)"
      ],
      "metadata": {
        "id": "HNLGNqdW6Hn8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicty = clf1.predict(x_test) \n",
        "report2 = metrics.classification_report(l_test,predicty , labels=[1,0], digits=3)\n",
        "print(report2)"
      ],
      "metadata": {
        "id": "lzoSniNj7E3E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf1.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "LxlJ3h5D8Dzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictLr = clf1.predict(text)"
      ],
      "metadata": {
        "id": "DkfgBcfo8b3G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submit1 = pd.DataFrame({'RevId': test['RevId'], 'Rating': predictLr})\n",
        "submit1.to_csv('/content/drive/MyDrive/Machine Learning/submit4.csv')\n",
        "submit1.head()"
      ],
      "metadata": {
        "id": "naVvq-6S8lhs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer\n",
        "from sklearn.svm import SVC\n",
        "svm = SVC(kernel='linear', C=0.2175, class_weight=None, verbose=True)\n",
        "step3 = []\n",
        "step3.append(('CountVectorizer', CountVectorizer(ngram_range=(1,5),max_df=0.5, min_df=5)))\n",
        "step3.append(('tfidf', TfidfTransformer(use_idf=False, sublinear_tf = True,norm='l2',smooth_idf=True)))\n",
        "step3.append(('classifiers',svm))\n",
        "clf2 = Pipeline(step3)"
      ],
      "metadata": {
        "id": "vgoHyAWd-VVa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf2.fit(x_train, l_train)"
      ],
      "metadata": {
        "id": "_CJ-WaCZ-_4O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict3 = clf2.predict(x_test) \n",
        "report3 = metrics.classification_report(l_test,predict3 , labels=[1,0], digits=3)\n",
        "print(report3)"
      ],
      "metadata": {
        "id": "hYHw0Qxo_ONE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}